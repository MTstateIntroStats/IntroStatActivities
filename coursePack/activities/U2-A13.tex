\def\theTopic{Weight Awareness}
\def\dayNum{13 }

\section{ What's Wrong With Your Weight?}


A study\footnote{Chang, V. W., \& Christakis,
  N. A. (2003). Self-perception of weight appropriateness in the
  United States. American Journal of Preventive Medicine, 24(4),
  332-339.}  in the {\em American Journal of Preventative Medicine},
  2003 looked at the self perception people have of their own weight.
  The participants in the {\em National Health and Nutrition
    Examination Survey} (NHNES) of the Center for Disease Control were
  asked  if they thought themselves underweight, overweight, or about
  the right weight.  Body Mass Index was also computed based on
  physical measurements, and the self--rating was compared to their
  actual classification.  The NHNES is a survey of about 5000 people each year
  which is representative of the entire US population.  The authors
  looked at data from 1999 when people were asked for their own
  perception of their weight. Interestingly, about the same
  proportion of men were wrong as women, but the way in which they
  were wrong might have a different pattern.  This table shows a
  random subsample taken from only the
  {\bf people who were wrong} in their self-perception.

  \begin{tabular}{|l|r|r|} \hline
       & \multicolumn{2}{|c|}{Gender} \\
Self Perception &Female  & Male \\ \hline
Over Estimated  &  50&  10  \\ \hline
Under Estimated &  20  & 59  \\ \hline
Total  &  70 & 69\\ \hline
  \end{tabular}
  
  The parameter of interest is $p_1 - p_2$, the true difference in
  proportions who over-estimate their weight between women and men. 
  We want to estimate how large the difference is, but first, as a
  review (as in Peanut Allergies), we'll do a test to see if the two
  proportions are equal. 
  \vspace{-.2in}
  \begin{enumerate}

  \item  State the null and alternative hypotheses in proper notation
    and in words.\\ \ 
    $H_0$
\begin{students}
 \ \   \vspace{1cm}\\
\end{students}
\begin{key}
  {\it $p_1 = p_2$  (NO HATS!) The true proportions of people who over
    estimate their weight (versus underestimate it) is zero.}
    \\
\end{key}
    $H_a$
\begin{students}
 \ \   \vspace{1cm}\\
\end{students}
\begin{key}
  {\it $p_1 \neq p_2$  (NO HATS!) The true proportions of people who over
    estimate their weight (versus underestimate it) are not equal. 
    } \\
\end{key}
    \item \label{testWeight}
   Go to the  web apps page:
   \url{https://jimrc.shinyapps.io/Sp-IntRoStats}
   and select \fbox{ Two Categ}, \fbox{Test or Estimate}.  Type our numbers into
   their cells so that \fbox{Success} is  ``over''--estimate,  \fbox{Group 1} is
   Female and change the other labels accordingly.  
   \begin{enumerate}
     \item \label{refWeights} What proportion of women who are wrong
       about their weight overestimate  (rather than underestimate) in this
       sample?  What proportion of men?  Take the difference between the two. 
\begin{students}
 \ \   \vspace*{2cm}\\
\end{students}
\begin{key}
  {\it Females: $\widehat{p}_1 = 0.714$, Males: $\widehat{p}_2 =
    0.145$,  Difference: $\widehat{p}_1  - \widehat{p}_2 =    0.569$,
    } 
\end{key}

   \item After checking the data, select \fbox{Test}, and generate  1000
     shuffles. Describe what the  computer does for a single
     ``shuffle''. 
\begin{students}
 \ \   \vspace*{3cm}\\
\end{students}
\begin{key}
  {\it  It randomly shuffles the 60 successes and 79 failures into
    fake Female and Male categories (70 females, and 69 males).}
\end{key}
% \item What does one little
%      rectangle in the histogram represent?
% \begin{students}
%  \ \   \vspace{2cm}\\
% \end{students}
% \begin{key}
%   {\it The value plotted is the difference in proportions between
%     success proportions for the fake Women and Men it created in one
%     random shuffle.}
% \end{key}

\item Why is the plot centered where it is centered?
\begin{students}
 \ \   \vspace{2cm}\\
\end{students}
\begin{key}
  {\it  Because the shuffling assumes $H_0$ is true, and that $p_1-p_2
    = 0$}
\end{key}



   \item Enter the observed difference in proportions, select the
     correct direction for the alternative, and write down the
     p--value   and strength of evidence. 
\begin{students}
 \\   \vspace{2cm}\\
\end{students}
\begin{key}
  {\it In 10000 shuffles my largest difference was 0.30, so on the
    upper side I get less than 1 in 10000. This is a two-sided
    alternative, so we have to double the one-sided count. Still the p--value
    is less than 2 in 10000 and a difference of 0.569 is enormously strong 
  evidence against the null hypothesis.    } \\
\end{key}

   \item  Which is the more plausible explanation:
     \begin{itemize}
     \item 
     These results   occurred just by chance (We just got unlucky and
     saw something weird) or
   \item 
     Men and Women who don't know what their weight is really do
     differ in their self-perception of being over versus under weight.
\begin{students}
       \vspace{2cm}
\end{students}
\begin{key}
 \\  {\it Men tend to underestimate and women to overestimate their
     weight relative to ``ideal'' weight.}  
\end{key}
     \end{itemize}
                    %%%  The S word  %%%%%%%%%%%%

    \item%  A shorthand report of statistical results often does not
      % report p--value and strength of evidence, but instead might say
      % ``the results were statistically significant at the 0.01
      % level''.  This means that the researchers determined before
      % collecting data that they wanted very strong evidence for any
      % effect, and that they would decide to ``reject $H_0$'' if the
      % p-value was less than 0.01, and that the p-value they computed
      % did turn out to be less than 0.01.  Here's a summary of the
      % steps:
      % \begin{itemize}
      % \item Decide what significance level ($\alpha$) to use,
      %   typically 0.10, 0.05 (most common) or 0.01, before collecting
      %   data.
      % \item Collect and analyze data to get a p--value.
      % \item Reject $H_o$ if the p--value $< \alpha$.  Note: we never
      %   ``accept'' $H_0$. If p--value $>\alpha$, we say that we ``Fail
      %   to reject $H_0$''.  The testing procedure can provide evidence
      %   that $H_0$ is false, but it is not intended to show that $H_0$
      %   is true.  It's like in our justice system when a defendant is
      %   found to be ``not guilty'' rather than ``innocent''.  The jury
      %   is saying that the evidence is not strong enough to
      %   ``demonstrate beyond a reasonable doubt'' that the defendant
      %   committed the crime.
      % \item If $H_0$ is rejected, some might report ``the results were
      %   statistically significant at the $\alpha$ significance
      %   level.'' (They should specify $\alpha$, but if they don't,
      %   we'd guess they used 0.05, the most common level.)
      %   This is not as informative as reporting the p--value, but you
      %   will read this in research articles, and need to know what it
      %   means. Reports for STAT 216  must contain the actual p--value.
      % \end{itemize}
      Suppose we had set $\alpha = .01$ prior to data collection. What
      is your ``decision'' about $H_0: p_1 = p_2$?  (Either reject or
      fail to reject) 
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
      \\ {\it Reject $H_0$.}\\
\end{key}
       State your conclusion about $H_0$ in the context of this
       situation. Be as specific   as possible about the true
       proportions overestimating their weight.
\begin{students}
 \ \   \vspace*{2cm}\\
\end{students}
\begin{key}
   {\it We conclude that when people are wrong about their weight, a
     much larger proportion of women than men say they are over,
     rather than under weight.}
\end{key}
\end{enumerate}

\item Now we will estimate the difference.  You might want to look
   back at Activity 7 to review the reasons we like interval estimates
   instead of point estimates.

   To build confidence intervals for a difference in proportions, we
   use the same app and data, just pick \fbox{Estimate}.

    \begin{enumerate}
      \item    \label{phatDiff} What is the point estimate for the
       difference in population    proportions? Use proper notation.
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
   $\widehat{p}_1  - \widehat{p}_2 =    0.569$
\end{key}

\item The output shows results from 1 resample of the data.
       They have generated  70 ``Female'' responses using $\phat_1 =
       50/70$ and 69 ``Male'' responses using $\phat_2 = 10/69$. What
       is the difference in proportions (over) for this one resample?
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
   \\ {\it AWV. (0.40 to 0.74) }  
\end{key}

       \item  Unlike the {\bf test} we did above, there is no assumption
         that proportions are the same for men and women.  Instead we
         use a bootstrap resample of the data on women and another bootstrap
         resample of the data on men to get an estimate of the
         sampling distribution. 
            \\  Generate more resamples until you are sure that you
            understand how they are created. For the 70 women in one
            resample, what is the probability that each will 
            ``OverEstimate'' her weight? 
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
  {\it Women: 0.714}\\
\end{key}  
For each man being resampled? 
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
  {\it  Men: 0.145}\\
\end{key} 

         How would you  resample from the women using 70 index cards?  Explain
         what to write on each card and how to randomly draw a card
         for each woman.
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
  {\it For Women, write ``Over'' on 50 cards, ``Under'' on 20  (or 5
    and 2) for 7 cards total). 
    Shuffle, draw one and record success if it's ``Over''.  Replace
    the card, shuffle, and draw the 2nd result. Continue til you get
    70 results and count up the number of ``Overs''.}
\end{key} 

        \item When you're sure you know what it is doing, click
          \fbox{\sf 1000} several times. Note that it
          adds more rather than getting rid of the old ones.
          Record center and SE of this distribution (upper right
          corner of plot).
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
   {\it I got mean$ = 0.569, SD = 0.068$}
\end{key}

\item Obtain four confidence intervals, one for each confidence
      level and write them here.
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
  \begin{tabular}{|r|c|}
    \hline
  Level & Interval \\
  80\%& (0.483, 0.656) \\
  90\% & (0.454, 0.684) \\
  95\% &(0.427, 0.699) \\
  99\% & (0.396, 0.742)
  \end{tabular}
\end{key}

\item Also compute the approximate 95\% CI using the $\pm 2 SE$ method:
  $\phat_1 - \phat_2 \pm 2 SE(\phat_1-\phat_2)$ 
\begin{students}
 \ \   \vspace*{1cm}\\
\end{students}
\begin{key}
   $ 0.57 \pm 2 * 0.069) =  (0.43, 0.71) $  
\end{key}
\item Compare the two 95\% intervals you created.
\begin{students}
 \ \   \vspace*{2cm}\\
\end{students}
\begin{key}
   {\it they should be quite close to each other.}\\
\end{key}

 \item Based on the 95\% CI, is it plausible that $p_1 = p_2$?
   Explain your answer by referring to your CI.
\begin{students}
 \ \   \vspace{2cm}\\
\end{students}
\begin{key}
  {\it The 95\% CI for $p_1 - p_2$ does not contain zero, so it is not
    plausible that $p_1 = p_2$. There is strong evidence that women
    tend to overestimate their weight when they are wrong, and men
    tend to underestimate.}
\end{key}
\item Interpret the meaning of this confidence interval in the context
  of this problem.  What do we mean when we say ``confidence''? 
\begin{students}
 \ \   \vspace{2cm}\\
\end{students}
\begin{key}
 {\it  We are 95\% confident that the difference in  true proportions
   (women's proportion minus men's) of people who are not in the range
   of ``ideal'' weights, but mistakenly think they are over weight is
   in the interval  (0.43, 0.71).  Our confidence is in the process, which we
   know captures the true mean 95\% of the time.}
\end{key}
    \end{enumerate}


\item Summarize the hypothesis test results in a report as in 
   question \ref{reportBullets} of the Activity 12.  Include all five
   bulleted points. 

  Note: This study did not randomly assign gender to people, it just
  observed whether they were male or female. The proper name for the
  test in \ref{testWeight} then is ``permutation'', not
  ``randomization'', and it was not 
  an experiment.  You may assume that the samples of men and women are
  representative of populations of people who are wrong about their
  weight status relative to ideal weight.\vspace{3in}

\end{enumerate}

\begin{center}
  {\bf Take Home Messages}
\end{center}
  \begin{itemize}
  \item With observational studies we can still conduct a permutation
    test, but it is not  a randomization test.
  \item As in Activity 12, we tested to see if  two proportions were
    equal. We had very strong evidence of a difference in proportions,
    but because we don't randomly assign gender, we can only say that
    we observed an {\bf association} between gender and over/under
    estimation, not that gender causes this to happen.
  \item The new part of this assignment is the confidence interval for
    the difference in proportions. 
  % \item Just reporting ``statistical significance'' has many problems.
  %   \begin{itemize}
  %   \item Statistical significance is not the same as {\bf importance}
  %     of the results.  Results could be very important, yet the
  %     p--value might not be very small, also small p--values could be
  %     attached to unimportant results.

  %   \item Journals must filter articles so that they only publish high quality
  %     research. For years, many journals thought that small p--values
  %     were an indicator of quality, but using p--values as a filter
  %     cuts out some important results. 

  %   \item By increasing sample size, we shrink the spread of the
  %     sampling distribution which tends to make p--values
  %     smaller. It's important to have large enough sample size to
  %     get a good view of the true parameter, but a really large sample
  %     lets us ``split hairs'' and label unimportant results as
  %     ``statistically significant''.

  %   \item The choice of a significance level must depend on the amount
  %     of evidence required before we're willing to give up $H_0$.  It
  %     is not the same for all situations.  The values commonly used are
  %     just based on tradition and are not especially useful.  
  %     A study with p--value 0.051 is not really different from a study
  %     of the same question which gives a p-value of 0.049.
      
  %   \end{itemize}
  \item We have just used confidence intervals 
    to estimate the difference between two proportions.  Recall from
    Activity 7: our confidence is in the process used to create the
    interval.  When used over and over on many random samples, 95\% of
    the intervals created will cover the true parameter of interest
    (here $p_1 - p_2$) and 5\% will miss the true parameter.

  \item When testing, we assume $H_0$ is true and the distribution is
    centered at 0.  When computing a bootstrap confidence interval, we
    are centered at the statistic, or point estimate, $\widehat{p}_1 -
    \widehat{p}_2$. 
 \item 
  Questions? What do you see as the key points of the lesson? \vfill

  \end{itemize}






\noindent
{\bf Assignment} \vspace{-.2in}
\begin{itemize}
%\item  D2Box 5 is due Feb 25.
%\item {\bf D2Quiz 6} is due Feb 29.  Fill it in online.
 %%  We strongly encourage you to get help in the Math Learning
 %%  Center.
\item Watch videos assigned on D2L.
%\item Watch video 4 under Unit 2 Examples.
\item Fill in the Simulation Confidence Interval box in column 3 of
  the Review Table. 
\item Read the next two pages before your next class.
\end{itemize}

