# Statistical Investigations for Paired Data


## Learning Outcomes

* Given a research question, construct the null and alternative hypotheses
  in words and using appropriate statistical symbols
  
* Describe and perform simulation-based hypothesis for paired quantitative data

* Interpret and evaluate a p-value

* Find a confidence interval for the mean difference using bootstrapping

* Use a confidence interval to determine the conclusion of a hypothesis test

## Terminology

The following terms will be covered in this activity.

* Mean difference

* Paired data

* Independent groups

* Shifted Null Distribution

For further explanation of these topics see Section 6.2 in the textbook.

## COVID-19 and Air Pollution

The social distancing efforts and stay-at-home directives to help combat the spread of COVID-19 have appeared to help 'flatten the curve' across the United States, albeit at a high cost to many individuals and businesses. The impact of these measures, though, goes far beyond the infection and death rates from the disease. You may have seen images comparing air quality in large international cities like Rome, Milan, Wuhan, and New Delhi such as the one pictured below which seem to indicate, perhaps unsurprisingly, that fewer people driving and factories being shut down have reduced air pollutants. 

![](images/air_pollution.png)

Have high population-density U.S. cities seen the same improved air quality conditions? To study this question, data was gathered from the U.S. Environmental Protection Agency (EPA) AirData website which records the ozone (O3) and fine particulate matter (PM2.5) values for cities across the U.S. These measures are used to calculate an air quality index (AQI) score for each city each day of the year. Thirty-three of the most densely populated U.S. cities were selected and the AQI score recorded for April 20, 2020 as well as the five-year median AQI score for April 20th (2015 - 2019). Note that higher AQI scores indicate worse air quality.

## Vocabulary Review
```{r}
Air <- read.csv("data/AirPollutionCOVID.csv")
```

```{r}
ggplot(data = Air,  #Dataset containing variables
       aes(y = Difference)) + #Variables to be used
    geom_boxplot() + #make a boxplot
    labs(title = "Boxplot of the Differences in AQI Scores",  #Title plot
         y = "Difference in air quality score")
```


|               |         Mean         | Standard deviation | Sample Size |
|:-------------:|:--------------------:|--------------------|-------------|
| Current       | $\bar{x}_1$ = 47.394 | $s_1$ = 14.107     | $n_1$ = 33  |
| 5 Year Median | $\bar{x}_2$ = 51.545 | $s_2$ = 17.447     | $n_2$ = 33  |
| Differences   | $\bar{x}_d$ = -4.152 | $s_d$ = 17.096     | $n_d$ = 33  |

1. What is the sample size? 

\vspace{0.5in}

2.  Identify the variables in this study.  What role do each have?

\vspace{1in}

3. Why is this treated as a paired study design and not two independent samples?

\vspace{1in}

4. Is this an experiment or observational study?

\vspace{0.5in}

## Ask a Research Question

5. What are the two competing possibilities to run a hypothesis test?

\vspace{1in}

6. Write the null hypothesis in words.

\vspace{1in}

7. What is the research question?

\vspace{1in}

8. Write the alternative hypothesis in notation.

\vspace{1in}


## Summarize and Visualize the Data 

9. Report the summary statistic for the data.  

\vspace{0.5in}

10. What notation is used for the value in question 9? 

\vspace{0.5in}


## Use statistical inferential methods to draw inferences from the data

To simulate the null distribution we will use a bootstrapping method - sampling with replacement from the data set.  Before bootstrapping we will need to shift the each data point by the difference $\mu_0 - \bar{x}$.  This will ensure that the simulated null distribution will be centered at the null value.  

11. Calculate the difference $\mu_0 - \bar{x}$.  Will we need to shift the data up or down?

\vspace{1in}

```{r, echo = FALSE}
paired_test <- function(data, shift = 0, direction = c("greater", "less", "two-sided"),
                        as_extreme_as, number_repetitions = 3, which_first = 1){
  if(!(direction %in% c("greater", "less", "two-sided")))
    stop("direction must be 'greater', 'less', or 'two-sided'")
  if(is.null(as_extreme_as))
    stop("Must enter cutoff value for 'as_extreme_as")
  if(number_repetitions < 1 | !(number_repetitions %%1 == 0))
    stop("number of repetitions must be positive and integer valued")
  if(!(which_first %in% 1:2))
    stop("which_first must equal 1 or 2 to indicate order of subtraction")
  if(is.vector(data)){
      warning("Assuming data entered is vector of differences")
      differences = data
      n = length(data)
  }else{
    if(ncol(data) < 2 | ncol(data) > 3)
      stop("Data should have two or three variables")
    if(ncol(data) == 3)
      data <- data[,2:3]
    differences = data[,which_first]-data[,ifelse(which_first == 1, 2, 1)]
    n = nrow(data)
  }
  
  obs_diff <- mean(differences)
  sim_diffs <- rep(NA, number_repetitions)
  for(i in 1:number_repetitions){
    sim_diffs[i] <- mean(sample(x = differences+shift, size = n, replace = TRUE))
  }
  
  count_extreme <- ifelse(direction == "greater", sum(sim_diffs >= as_extreme_as),
                          ifelse(direction == "less", sum(sim_diffs <= as_extreme_as),
                                 sum(sim_diffs <= -abs(as_extreme_as)) + 
                                   sum(sim_diffs >= abs(as_extreme_as))))
                          
  h <- hist(sim_diffs, plot = FALSE, breaks = "FD")
  if(direction == "two-sided"){
    cuts <- cut(h$breaks, c(-Inf, -abs(as_extreme_as), abs(as_extreme_as), Inf))
    col.vec <- rep("grey80", length(cuts))
    col.vec[cuts == levels(cuts)[1]] ="red"
    col.vec[cuts == levels(cuts)[3]] ="red"
  }else if (direction == "greater"){
    cuts <- cut(h$breaks, c(-Inf, as_extreme_as, Inf))
    col.vec <- rep("grey80", length(cuts))
    col.vec[cuts == levels(cuts)[2]] ="red"
  }else{
    cuts <- cut(h$breaks, c(-Inf, as_extreme_as, Inf))
    col.vec <- rep("grey80", length(cuts))
    col.vec[cuts == levels(cuts)[1]] ="red"
  }
  plot(h, col = col.vec, main = "", ylab = "", xlab = "Average Difference",
       yaxt = "n", sub = paste("Count = ", 
                       count_extreme, 
                       "/", number_repetitions, " = ", 
                       round(count_extreme/number_repetitions,4), sep = ""))
  
   legend("topright", legend = c(paste("Mean =", round(mean(sim_diffs, na.rm = T),3)),
                              paste("SD =", round(sd(sim_diffs, na.rm = T),3))),
         col = "white", bty = "n")
   if(direction == "two-sided"){
     abline(v = abs(as_extreme_as), col= "red", lwd = 2)
     abline(v = -abs(as_extreme_as), col= "red", lwd = 2)
   }else{
     abline(v = as_extreme_as, col= "red", lwd = 2)
   }
}


paired_bootstrap_CI <- function(data, number_repetitions = 100, confidence_level = 0.95,
                                which_first = 1){
  if(number_repetitions < 1 | !(number_repetitions %%1 == 0))
    stop("number of repetitions must be positive and integer valued")
  if(confidence_level < 0 | confidence_level > 1)
    stop("Confidence level must be given in decimal form")
  if(!(which_first %in% 1:2))
    stop("which_first must equal 1 or 2 to indicate order of subtraction")
  if(is.vector(data)){
      warning("Assuming data entered is vector of differences")
      differences = data
      n = length(data)
  }else{
    if(ncol(data) < 2 | ncol(data) > 3)
      stop("Data should have two or three variables")
    if(ncol(data) == 3)
      data <- data[,2:3]
    differences = data[,which_first]-data[,ifelse(which_first == 1, 2, 1)]
    n = nrow(data)
  }
  
  
  obs_diff <- mean(differences)
  sim_diffs <- rep(NA, number_repetitions)
  
  for(i in 1:number_repetitions){
    boot_samp <- sample(differences, n, replace = TRUE)
    sim_diffs[i] <- mean(boot_samp)
  }
  
  low_ci <- quantile(sim_diffs, (1-confidence_level)/2)
  high_ci <- quantile(sim_diffs, 1-(1-confidence_level)/2)
                          
  h <- hist(sim_diffs, plot = FALSE, breaks = "FD")
 
  cuts <- cut(h$breaks, c(-Inf, low_ci, high_ci, Inf))
  col.vec <- rep("grey80", length(cuts))
  col.vec[cuts == levels(cuts)[1]] ="red"
  col.vec[cuts == levels(cuts)[3]] ="red"
 
  break_range <- max(h$breaks) - min(h$breaks)
  plot(h, col = col.vec, main = "", ylab = "", xlim = c(min(min(h$breaks), low_ci-break_range/6),
       max(max(h$breaks), high_ci+break_range/6)),
       xlab = "Bootstrap Mean Difference",
       yaxt = "n", sub = paste0(100*confidence_level, "% CI: (", 
                       round(low_ci,3), ", ", round(high_ci,3), ")"))
  abline(v = c(low_ci, high_ci), col= "red", lwd = 2)

  cutoff_label <- c(paste(round(100*(1-confidence_level)/2, 1), "percentile"), 
                    paste(round(100*(1-(1-confidence_level)/2), 1), "percentile"))
  text(c(low_ci, high_ci), 
           rep(max(h$counts),2), labels = cutoff_label,
           pos = c(2, 4), cex = .75)
}

```

The image below gives the null distribution from one possible set of 1000 bootstrap samples:

```{r, warning = FALSE}
paired_test(data = Air$Difference,   #Vector of differences or dataset with column for each group
            shift = 4.152,   #Shift needed for bootstrap hypothesis test
            direction = "less",  #Direction of alternative
            as_extreme_as = -4.152,  #Observed statistic
            number_repetitions = 1000,  #Number of draws for null distribution
            which_first = 1)  #Not needed when using calculated differences
```


12. Explain why the null distribution is centered at zero. 

\vspace{1in}

13. What proportion of samples are beyond the sample mean difference in AQI Scores for current scores minus 5 year median scores?

\vspace{1in}

14. Interpret the p-value in the context of the problem.

\vspace{1in}

15. How much evidence does this provide for improved air quality in US cities?

\vspace{1in}

16. Write out the parameter of interest in context of the study.

\vspace{1in}

```{r, warning = FALSE}
paired_bootstrap_CI(data = Air$Difference, #Enter vector of differences
                    number_repetitions = 1000, #Number of bootstrap samples for CI
                    confidence_level = 0.99,  #Confidence level in decimal form
                    which_first = 1)  #Not needed when entering vector of differences
```

17.  Use bootstrapping to find a 99% confidence interval for the parameter of interest.  Fill in the data, number of bootstrap samples, and confidence level.  Report the confidence interval in interval notation.

\vspace{1in}

## Communicate the results and answer the research question.

18. Interpret the 99% confidence interval in the following figure in the context of the problem.

\vspace{1in}


19.  Write a paragraph summarizes the results of this study.  Be sure to include:

* Summary statistic

* P-value

* Interpretation of the p-value

* Confidence Interval

* Interpretation of the confidence interval

* Conclusion in context

\vspace{3in}

## Revisit and Look Forward




## Additional Notes

Use this space to summarize your thoughts and take additional notes on today's activity.
